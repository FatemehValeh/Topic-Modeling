{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REIbpkNh7C0f",
        "outputId": "e839e823-f7c8-4c69-846d-08d8c43af218",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02LDrjPhVjOy",
        "outputId": "ec3acf62-c421-42b0-8a3f-d77335729c0b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIWpihVhnWg3",
        "outputId": "0a832568-089d-4611-9bd4-c902541891ca",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contextualized-topic-models in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models) (1.26.4)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models) (0.20.0+cu121)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models) (2.5.0+cu121)\n",
            "Requirement already satisfied: gensim==4.2.0 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models) (4.2.0)\n",
            "Requirement already satisfied: sentence-transformers>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models) (3.2.1)\n",
            "Requirement already satisfied: wordcloud>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models) (1.9.3)\n",
            "Requirement already satisfied: matplotlib>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.56.0 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models) (4.66.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models) (1.14.1)\n",
            "Requirement already satisfied: ipywidgets==7.5.1 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models) (7.5.1)\n",
            "Requirement already satisfied: ipython==8.10.0 in /usr/local/lib/python3.10/dist-packages (from contextualized-topic-models) (8.10.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0->contextualized-topic-models) (7.0.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized-topic-models) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized-topic-models) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized-topic-models) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized-topic-models) (0.1.7)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized-topic-models) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized-topic-models) (3.0.48)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized-topic-models) (2.18.0)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized-topic-models) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized-topic-models) (5.7.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==8.10.0->contextualized-topic-models) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==7.5.1->contextualized-topic-models) (5.5.6)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==7.5.1->contextualized-topic-models) (5.10.4)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==7.5.1->contextualized-topic-models) (3.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.3->contextualized-topic-models) (2.8.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.1.1->contextualized-topic-models) (4.44.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.1.1->contextualized-topic-models) (1.5.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.1.1->contextualized-topic-models) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->contextualized-topic-models) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6.0->contextualized-topic-models) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.1.1->contextualized-topic-models) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.1.1->contextualized-topic-models) (2.32.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.5.1->contextualized-topic-models) (6.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython==8.10.0->contextualized-topic-models) (0.8.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (5.7.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==8.10.0->contextualized-topic-models) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython==8.10.0->contextualized-topic-models) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.3->contextualized-topic-models) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim==4.2.0->contextualized-topic-models) (1.16.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.1.1->contextualized-topic-models) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.1.1->contextualized-topic-models) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.1.1->contextualized-topic-models) (0.19.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (6.5.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->contextualized-topic-models) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.1.1->contextualized-topic-models) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.1.1->contextualized-topic-models) (3.5.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython==8.10.0->contextualized-topic-models) (2.1.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython==8.10.0->contextualized-topic-models) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython==8.10.0->contextualized-topic-models) (0.2.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (0.20.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->ipywidgets==7.5.1->contextualized-topic-models) (4.3.6)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=2.1.1->contextualized-topic-models) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=2.1.1->contextualized-topic-models) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=2.1.1->contextualized-topic-models) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=2.1.1->contextualized-topic-models) (2024.8.30)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.3.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (21.2.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->contextualized-topic-models) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install contextualized-topic-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SYodIERMs9kL",
        "outputId": "bcf25956-d8fa-445a-e5c4-0218744161d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.8.39)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.5.2)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (3.2.1)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.5)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.5.6)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (24.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.44.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.5.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (10.4.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.6.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.12.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install bertopic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SfEqedlVvRM",
        "outputId": "d13df3d1-9a75-46d9-8c82-69cbcbda00d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.14.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy==1.10.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAyaiiafWAi4",
        "outputId": "afec4ea8-bb4c-413a-8677-cc8630c37837"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.10.1\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy==1.10.1) (1.26.4)\n",
            "Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed scipy-1.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from contextualized_topic_models.models.ctm import CTM\n",
        "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "VkhzeUznOx-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGHn2yAvf1cR"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"/content/cleaned_labeled_dataset.xlsx\")\n",
        "column_name = 'cleaned_tweets'\n",
        "label_column = 'label'  # Column containing true labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LDA"
      ],
      "metadata": {
        "id": "IP0z6OWhOqBm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE-gjRqvgFcM"
      },
      "outputs": [],
      "source": [
        "# Ensure each tweet is a list of tokens (words)\n",
        "df[column_name] = df[column_name].apply(lambda x: x.split() if isinstance(x, str) else x)\n",
        "\n",
        "# Create a dictionary and a corpus for LDA\n",
        "dictionary = corpora.Dictionary(df[column_name])\n",
        "corpus = [dictionary.doc2bow(tweet) for tweet in df[column_name]]\n",
        "\n",
        "# Set the number of topics\n",
        "NUM_TOPICS = 7\n",
        "\n",
        "# Train the LDA model\n",
        "lda_model = LdaModel(corpus, num_topics=NUM_TOPICS, id2word=dictionary, passes=15)\n",
        "\n",
        "# Step 1: Create a DataFrame for Topic Words with Document Counts\n",
        "\n",
        "# Get the topic words and their scores\n",
        "topics = lda_model.show_topics(num_topics=NUM_TOPICS, num_words=10, formatted=False)\n",
        "\n",
        "# Create a DataFrame to store each topic's most important words and document count\n",
        "topic_words_df = pd.DataFrame(columns=['Topic_ID', 'Top_Words', 'Document_Count'])\n",
        "\n",
        "for topic_id, words in topics:\n",
        "    # Get top words and their scores\n",
        "    top_words = \", \".join([f\"{word}: {round(score, 4)}\" for word, score in words])\n",
        "\n",
        "    # Calculate the number of documents associated with this topic\n",
        "    doc_count = sum([1 for doc in corpus if lda_model.get_document_topics(doc, minimum_probability=0.1)[0][0] == topic_id])\n",
        "\n",
        "    # Add to DataFrame\n",
        "    topic_words_df = pd.concat([topic_words_df, pd.DataFrame({'Topic_ID': [topic_id],\n",
        "                                                             'Top_Words': [top_words],\n",
        "                                                             'Document_Count': [doc_count]})])\n",
        "\n",
        "# Step 2: Add Topic Columns to the Original DataFrame\n",
        "\n",
        "# Initialize lists to store new columns\n",
        "topic_ids = []\n",
        "topic_representative_words = []\n",
        "topic_confidences = []\n",
        "\n",
        "# Iterate through each document in the corpus to get its dominant topic\n",
        "for doc in corpus:\n",
        "    # Get the most dominant topic for the document with its confidence score\n",
        "    topics_for_doc = lda_model.get_document_topics(doc)\n",
        "    dominant_topic_id, confidence = sorted(topics_for_doc, key=lambda x: x[1], reverse=True)[0]\n",
        "\n",
        "    # Get representative words with their scores\n",
        "    topic_words_with_scores = lda_model.show_topic(dominant_topic_id, topn=10)\n",
        "    representative_words = \", \".join([f\"{word}: {round(score, 4)}\" for word, score in topic_words_with_scores])\n",
        "\n",
        "    # Append values to lists\n",
        "    topic_ids.append(dominant_topic_id)\n",
        "    topic_representative_words.append(representative_words)\n",
        "    topic_confidences.append(confidence)\n",
        "\n",
        "# Add new columns to the original DataFrame\n",
        "df['Topic_ID'] = topic_ids\n",
        "df['Topic_Representative_Words'] = topic_representative_words\n",
        "df['Topic_Confidence'] = topic_confidences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC9VCWiwiA9U"
      },
      "outputs": [],
      "source": [
        "topic_words_df.to_excel('LDA_topic_words_df.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8OBCnyMiIg7"
      },
      "outputs": [],
      "source": [
        "df.to_excel('LDA_labeled_df.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-x1rc2jci9kW"
      },
      "outputs": [],
      "source": [
        "# Calculate the purity for each topic\n",
        "\n",
        "# Group by Topic_ID and calculate the purity for each topic\n",
        "purity_data = []\n",
        "for topic_id in df['Topic_ID'].unique():\n",
        "    # Get the subset of the dataframe corresponding to the current topic\n",
        "    topic_df = df[df['Topic_ID'] == topic_id]\n",
        "\n",
        "    # Count the occurrences of each label within the topic\n",
        "    label_counts = topic_df['label'].value_counts()\n",
        "\n",
        "    # Identify the majority label and its count\n",
        "    majority_label_count = label_counts.max()\n",
        "    topic_size = len(topic_df)\n",
        "\n",
        "    # Calculate the purity\n",
        "    purity = majority_label_count / topic_size\n",
        "\n",
        "    # Store the results\n",
        "    purity_data.append({'Topic_ID': topic_id, 'Purity': purity, 'Majority_Label': label_counts.idxmax(), 'Topic_Size': topic_size})\n",
        "\n",
        "# Create a DataFrame to store purity results\n",
        "purity_df = pd.DataFrame(purity_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "992VdMshjCts"
      },
      "outputs": [],
      "source": [
        "purity_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec5s8l86nEXf"
      },
      "source": [
        "## CTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKz70wN9nF3F"
      },
      "outputs": [],
      "source": [
        "# Step 1: Prepare Data for CTM\n",
        "\n",
        "# Convert cleaned tweets to a list of strings (required format for CTM)\n",
        "documents = df[column_name].tolist()\n",
        "\n",
        "# Instantiate the data preparation object\n",
        "# tp = TopicModelDataPreparation(\"HooshvareLab/bert-fa-zwnj-base\")  # Using MiniLM sentence transformer\n",
        "tp = TopicModelDataPreparation(\"myrkur/sentence-transformer-parsbert-fa\")  # Using MiniLM sentence transformer\n",
        "\n",
        "# Prepare training data for CTM\n",
        "training_dataset = tp.fit(text_for_contextual=documents, text_for_bow=documents)\n",
        "\n",
        "# Step 2: Train the CTM Model\n",
        "\n",
        "# Set the number of topics\n",
        "NUM_TOPICS = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9BSeXLeqBWs"
      },
      "outputs": [],
      "source": [
        "# Get topic distribution for each document\n",
        "topic_distributions = ctm_model.get_doc_topic_distribution(training_dataset)\n",
        "\n",
        "# Assign the most probable topic to each document\n",
        "dominant_topic_ids = topic_distributions.argmax(axis=1)  # Get the index of the highest probability topic\n",
        "\n",
        "# Add Topic_ID to the original DataFrame\n",
        "df['Topic_ID'] = dominant_topic_ids\n",
        "\n",
        "# Get the word distribution matrix for topics (rows are topics, columns are words)\n",
        "topic_word_distribution = ctm_model.get_topic_word_distribution()\n",
        "\n",
        "# Create a vocabulary list\n",
        "vocab = tp.vocab\n",
        "\n",
        "# Create a dictionary to store topic representative words with confidence scores\n",
        "topic_representative_words = {}\n",
        "for idx, topic_dist in enumerate(topic_word_distribution):\n",
        "    # Get the top 10 words for each topic with their probabilities\n",
        "    top_word_indices = topic_dist.argsort()[-10:][::-1]\n",
        "    representative_words = \", \".join([f\"{vocab[i]}: {round(topic_dist[i], 4)}\" for i in top_word_indices])\n",
        "    topic_representative_words[idx] = representative_words\n",
        "\n",
        "# Add Topic_Representative_Words to the DataFrame based on the dominant topic\n",
        "df['Topic_Representative_Words'] = df['Topic_ID'].map(topic_representative_words)\n",
        "\n",
        "# Calculate confidence for each document's dominant topic\n",
        "df['Topic_Confidence'] = [topic_distributions[i, topic_id] for i, topic_id in enumerate(dominant_topic_ids)]\n",
        "\n",
        "# Step 4: Calculate Purity for Each Topic\n",
        "\n",
        "purity_data = []\n",
        "for topic_id in df['Topic_ID'].unique():\n",
        "    # Get the subset of the dataframe corresponding to the current topic\n",
        "    topic_df = df[df['Topic_ID'] == topic_id]\n",
        "\n",
        "    # Count the occurrences of each label within the topic\n",
        "    label_counts = topic_df[label_column].value_counts()\n",
        "\n",
        "    # Identify the majority label and its count\n",
        "    majority_label_count = label_counts.max()\n",
        "    topic_size = len(topic_df)\n",
        "\n",
        "    # Calculate the purity\n",
        "    purity = majority_label_count / topic_size\n",
        "\n",
        "    # Store the results\n",
        "    purity_data.append({\n",
        "        'Topic_ID': topic_id,\n",
        "        'Purity': purity,\n",
        "        'Majority_Label': label_counts.idxmax(),\n",
        "        'Topic_Size': topic_size\n",
        "    })\n",
        "\n",
        "# Create a DataFrame to store purity results\n",
        "purity_df = pd.DataFrame(purity_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GHJYuSi5Grz"
      },
      "outputs": [],
      "source": [
        "purity_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TWU__6QqFIl"
      },
      "outputs": [],
      "source": [
        "purity_df.to_excel('CTM_purity_df.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiI9L6x8qIlP"
      },
      "outputs": [],
      "source": [
        "df.to_excel('CTM_labeled_df.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atMnSzN3sH7s"
      },
      "source": [
        "## BERTopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mji0rJSksKkl"
      },
      "outputs": [],
      "source": [
        "embedding_model = SentenceTransformer(\"myrkur/sentence-transformer-parsbert-fa\")\n",
        "cluster_model = KMeans(n_clusters=7)\n",
        "\n",
        "docs = df['cleaned_tweets'].tolist()\n",
        "\n",
        "topic_model = BERTopic(embedding_model=embedding_model, hdbscan_model=cluster_model, calculate_probabilities=True)\n",
        "topics, probs = topic_model.fit_transform(docs)\n",
        "\n",
        "info_df = topic_model.get_topic_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEz1fOOCwlec"
      },
      "outputs": [],
      "source": [
        "info_df.to_excel('BERTopic_kmeans_info_df.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ckaHd20uXD7"
      },
      "outputs": [],
      "source": [
        "info_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QScAS-QvvI6E"
      },
      "outputs": [],
      "source": [
        "document_info = topic_model.get_document_info(docs)\n",
        "document_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT5DlYpHvMlD"
      },
      "outputs": [],
      "source": [
        "document_info.to_excel('BERTopic_kmeans_document_df.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9rkrU_yv0GA"
      },
      "outputs": [],
      "source": [
        "# Ensure 'cleaned_tweets' and 'Document' columns have the same type before merging\n",
        "df['cleaned_tweets'] = df['cleaned_tweets'].astype(str)\n",
        "document_info['Document'] = document_info['Document'].astype(str)\n",
        "\n",
        "# Perform the merge operation\n",
        "merged_df = pd.merge(df, document_info, left_on='cleaned_tweets', right_on='Document', how='left')\n",
        "merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsc0eP6lu_ZA"
      },
      "outputs": [],
      "source": [
        "# Step 1: Initialize a list to store purity results for each topic\n",
        "purity_data = []\n",
        "\n",
        "# Step 2: Iterate over each unique topic in the DataFrame\n",
        "for topic_id in merged_df['Topic'].unique():\n",
        "\n",
        "    # Step 3: Get the subset of the dataframe corresponding to the current topic\n",
        "    topic_df = merged_df[merged_df['Topic'] == topic_id]\n",
        "\n",
        "    # Step 4: Count the occurrences of each label within the topic\n",
        "    label_counts = topic_df['label'].value_counts()\n",
        "\n",
        "    # Step 5: Identify the majority label and its count\n",
        "    majority_label_count = label_counts.max()\n",
        "    majority_label = label_counts.idxmax()\n",
        "    topic_size = len(topic_df)\n",
        "\n",
        "    # Step 6: Calculate purity for this topic\n",
        "    purity = majority_label_count / topic_size\n",
        "\n",
        "    # Step 7: Store the results in the purity_data list\n",
        "    purity_data.append({\n",
        "        'Topic_ID': topic_id,\n",
        "        'Purity': purity,\n",
        "        'Majority_Label': majority_label,\n",
        "        'Topic_Size': topic_size\n",
        "    })\n",
        "\n",
        "# Step 8: Create a DataFrame to store purity results\n",
        "purity_df = pd.DataFrame(purity_data)\n",
        "\n",
        "# Step 9: Display the purity DataFrame\n",
        "print(\"Purity DataFrame:\")\n",
        "purity_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}